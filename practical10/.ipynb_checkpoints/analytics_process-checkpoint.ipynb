{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Mining\n",
    "\n",
    "## Practical 10\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Useful Packages\n",
    "\n",
    "On advantage of python is the many packages that can make implementing solutions to data mining problems efficient.\n",
    "\n",
    "In the previous pracs we focused on a few key packages here we introduce some more that are useful generally to you in the future.\n",
    "\n",
    "In this notebook, we are going to introduce some additional packages that may be useful for you going forward.\n",
    "\n",
    "See the list [here](https://wiki.python.org/moin/UsefulModules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Functions\n",
    "* `time` and `datetime` for calendar and date processing\n",
    "* `os` and `sys` to run commands in computer's operating system and access programs \n",
    "* `math` for mathematical calculations\n",
    "* `re` regular experessions\n",
    "* `pickle` store python data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import decimal\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import re\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Loading and web programming\n",
    "* `csv`, `json`, and `xml` handling files of specific formats quickly\n",
    "* `pandas` data tables\n",
    "* Beautiful Soup 4 (`bs4`) and `urllib2` for handling HTML data and web crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import xml\n",
    "import pandas as pd\n",
    "import bs4\n",
    "#import urllib.request\n",
    "#import urllib.error\n",
    "#import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import rando\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn is a library with advanced visualisation features...\n",
    "\n",
    "[see complete example](http://seaborn.pydata.org/examples/many_pairwise_correlations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3cd19fb00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3c846b320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "# Random sample with a twist\n",
    "a = random.sample(range(0,100),  25)\n",
    "b = random.sample(range(0,100),  25)\n",
    "temp_c = random.sample(range(0,100),  25)\n",
    "c = [x - y for x, y in zip(temp_c, b)]\n",
    "temp_d = random.sample(range(0,100),  25)\n",
    "d = [x - y for x, y in zip(temp_d, a)]\n",
    "\n",
    "# Correlations using Pandas\n",
    "dataset = pd.DataFrame(list(zip(a,b,c,d)),columns=['a','b','c','d'])\n",
    "correlations = dataset.corr()\n",
    "\n",
    "# Seaborn plot\n",
    "seaborn.heatmap(correlations, cmap=seaborn.diverging_palette(220, 10, as_cmap=True), linewidths=.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Scientific Computing\n",
    "Handling arrays and vectorised operations plus much more.\n",
    "* `numpy`\n",
    "* `scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import nltk  # Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Machine Learning\n",
    "\n",
    "* sci-kit learn (`sklearn`) is one of the most popular packages for machine learning\n",
    "* There are many others specialised for particular tasks or for instance to get faster performance or other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import statsmodels\n",
    "# import theano\n",
    "# import tensorflow  #(advanced) neural network library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CRISP Data Mining Process stages\n",
    "\n",
    "It is very useful to follow a structured process in performing data mining.\n",
    "\n",
    "* Business understanding\n",
    "* Data understanding\n",
    "* Data preparation\n",
    "* Modelling\n",
    "* Evaluation\n",
    "* Deployment\n",
    "\n",
    "<img src=\"images/workflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Cleaning\n",
    "We discuss data processing, cleaning, and exploration in our very first class and went on to touch on it a few more times throughout the semester. However, I'd like to review some of this again given some common questions I've been getting.\n",
    "\n",
    "### 3.1. Structured Data\n",
    "Almost all of the data we have dealt with so far can be called *structured* data. This means that every record in the data set is organized and structured in a machine readable way.  Very often \"structured\" corresponds to being organized in a common database structure (essentially one or more possibly related tables). \n",
    "\n",
    "The four most popular ways of storing structured data are:\n",
    "\n",
    "- **.csv or .tsv** - Can be thought of as rows and columns, where each column will represent a single feature. All rows should have a value for each column (although some analytics methods will deal with blanks).\n",
    "- **JSON** - Looks similar to Python dictionaries. Each row can have an unordered list of `key:value`s\n",
    "- **XML** - Tagging language that looks something like HTML. More similar to JSON than to csv or tsv.\n",
    "- **A full-blown relational database** -- A relational database has tables for entities and for relationships, with keys (identifiers) related the tables to each other.  Examples of common databases are mysql and commercial databased provided by Oracle, Microsoft, etc.\n",
    "\n",
    "The layout of any of these data types might seem straightforward, but there can be tons of complications. \n",
    "\n",
    "**A file ending in `.csv` does *not* mean that it will be well structured. It is still just a text file.**\n",
    "\n",
    "There is a data file in the `/data/` folder called `strings_*.csv`. This csv file has no header. However, we know the columns are: 'age', 'satisfaction', 'location', 'time_spent', 'income', 'bio', 'purchased'. Let's see it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.0,neutral,eu,3.952074059758619,-19.48620784914078,Sodales \"vivamus\" in, risus molestie, egestas in.,0\n",
      "28.0,neutral,sa,3.5295183836057595,51.284180040232215,Pellentesque arcu sed.,1\n",
      "37.0,high,sa,4.254526317975149,97.34526006557826,Neque odio, in nulla, lorem nec.,0\n",
      "42.0,high,sa,4.924077485580787,80.24260604790156,Lorem non pretium.,0\n",
      "56.0,high,af,6.436250132712625,42.78962533750958,Sem dictum dolor.,0\n",
      "40.0,neutral,af,4.576757605316351,-1.0876572412988317,Neque condimentum.,1\n",
      "69.0,neutral,eu,5.365851342999525,-15.770934329395772,Nisl fames ipsum, amet laoreet.,0\n",
      "44.0,high,sa,2.912293368604344,73.85944600120466,Arcu quisque, vitae turpis integer, fusce luctus.,1\n",
      "63.0,neutral,eu,4.376757476733249,3.9510213482794034,Feugiat diam, at ipsum.,0\n",
      "56.0,neutral,eu,3.461138913269333,-46.426105926443086,Metus elit.,1\n"
     ]
    }
   ],
   "source": [
    "!head data/strings_ugly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>63.0</th>\n",
       "      <th>neutral</th>\n",
       "      <th>eu</th>\n",
       "      <th>3.952074059758619</th>\n",
       "      <th>-19.48620784914078</th>\n",
       "      <th>Sodales \"vivamus\" in</th>\n",
       "      <th>risus molestie</th>\n",
       "      <th>egestas in.</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sa</td>\n",
       "      <td>3.529518</td>\n",
       "      <td>51.284180</td>\n",
       "      <td>Pellentesque arcu sed.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.0</td>\n",
       "      <td>high</td>\n",
       "      <td>sa</td>\n",
       "      <td>4.254526</td>\n",
       "      <td>97.345260</td>\n",
       "      <td>Neque odio</td>\n",
       "      <td>in nulla</td>\n",
       "      <td>lorem nec.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>high</td>\n",
       "      <td>sa</td>\n",
       "      <td>4.924077</td>\n",
       "      <td>80.242606</td>\n",
       "      <td>Lorem non pretium.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>high</td>\n",
       "      <td>af</td>\n",
       "      <td>6.436250</td>\n",
       "      <td>42.789625</td>\n",
       "      <td>Sem dictum dolor.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>af</td>\n",
       "      <td>4.576758</td>\n",
       "      <td>-1.087657</td>\n",
       "      <td>Neque condimentum.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   63.0  neutral  eu  3.952074059758619  -19.48620784914078  \\\n",
       "0  28.0  neutral  sa           3.529518           51.284180   \n",
       "1  37.0     high  sa           4.254526           97.345260   \n",
       "2  42.0     high  sa           4.924077           80.242606   \n",
       "3  56.0     high  af           6.436250           42.789625   \n",
       "4  40.0  neutral  af           4.576758           -1.087657   \n",
       "\n",
       "     Sodales \"vivamus\" in  risus molestie  egestas in.    0  \n",
       "0  Pellentesque arcu sed.               1          NaN  NaN  \n",
       "1              Neque odio        in nulla   lorem nec.  0.0  \n",
       "2      Lorem non pretium.               0          NaN  NaN  \n",
       "3       Sem dictum dolor.               0          NaN  NaN  \n",
       "4      Neque condimentum.               1          NaN  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/strings_ugly.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That can't be right. If you look at the data you'll see that there are commas in one of the fields. Encapsulate and escape them.  (One would do this manually, or by building regular expressions (for example, noting that the truly delimiting quotes always are preceded or followed by a comma), or a combination of both (there might be a spurious quote followed by a comma within a string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>location</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>income</th>\n",
       "      <th>bio</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>eu</td>\n",
       "      <td>3.952074</td>\n",
       "      <td>-19.486208</td>\n",
       "      <td>Sodales \"vivamus\" in, risus molestie, egestas in.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sa</td>\n",
       "      <td>3.529518</td>\n",
       "      <td>51.284180</td>\n",
       "      <td>Pellentesque arcu sed.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>high</td>\n",
       "      <td>sa</td>\n",
       "      <td>4.254526</td>\n",
       "      <td>97.345260</td>\n",
       "      <td>Neque odio, in nulla, lorem nec.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>high</td>\n",
       "      <td>sa</td>\n",
       "      <td>4.924077</td>\n",
       "      <td>80.242606</td>\n",
       "      <td>Lorem non pretium.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>high</td>\n",
       "      <td>af</td>\n",
       "      <td>6.436250</td>\n",
       "      <td>42.789625</td>\n",
       "      <td>Sem dictum dolor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age satisfaction location  time_spent     income  \\\n",
       "0  63.0      neutral       eu    3.952074 -19.486208   \n",
       "1  28.0      neutral       sa    3.529518  51.284180   \n",
       "2  37.0         high       sa    4.254526  97.345260   \n",
       "3  42.0         high       sa    4.924077  80.242606   \n",
       "4  56.0         high       af    6.436250  42.789625   \n",
       "\n",
       "                                                 bio  purchased  \n",
       "0  Sodales \"vivamus\" in, risus molestie, egestas in.          0  \n",
       "1                             Pellentesque arcu sed.          1  \n",
       "2                   Neque odio, in nulla, lorem nec.          0  \n",
       "3                                 Lorem non pretium.          0  \n",
       "4                                  Sem dictum dolor.          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "column_names = ['age', 'satisfaction', 'location', 'time_spent', 'income', 'bio', 'purchased']\n",
    "\n",
    "# quotechar = The character used to denote the start and end of a quoted item. Quoted items can include \n",
    "#             the delimiter and it will be ignored. In this case \" is considered as the quoting character.\n",
    "\n",
    "# escapechar = One-character string used to escape delimiter. In this cases spaces won't be considered 'delimiter'.\n",
    "\n",
    "data = pd.read_csv(\"data/strings_escaped.csv\", names=column_names, quotechar=\"\\\"\", escapechar=\"\\\\\")\n",
    "\n",
    "\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data cleaning can go on for a long time until you find all the small nuances to your data file. Notice that we keep adding levels of complexity to our parser. Doing this at the command line is very tricky, which is why using pandas and `read_csv()` are very nice. A lot of the problems we just saw are unfortunately solved by editing the raw data to conform to some kind of standards. Regular expressions can be very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have three fields that aren't numeric. Since we need numeric features for many of our machine learning algorithms, let's convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>location</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>income</th>\n",
       "      <th>bio</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>eu</td>\n",
       "      <td>3.952074</td>\n",
       "      <td>-19.486208</td>\n",
       "      <td>Sodales \"vivamus\" in, risus molestie, egestas in.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>sa</td>\n",
       "      <td>3.529518</td>\n",
       "      <td>51.284180</td>\n",
       "      <td>Pellentesque arcu sed.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>sa</td>\n",
       "      <td>4.254526</td>\n",
       "      <td>97.345260</td>\n",
       "      <td>Neque odio, in nulla, lorem nec.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>sa</td>\n",
       "      <td>4.924077</td>\n",
       "      <td>80.242606</td>\n",
       "      <td>Lorem non pretium.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>af</td>\n",
       "      <td>6.436250</td>\n",
       "      <td>42.789625</td>\n",
       "      <td>Sem dictum dolor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  satisfaction location  time_spent     income  \\\n",
       "0  63.0             0       eu    3.952074 -19.486208   \n",
       "1  28.0             0       sa    3.529518  51.284180   \n",
       "2  37.0             1       sa    4.254526  97.345260   \n",
       "3  42.0             1       sa    4.924077  80.242606   \n",
       "4  56.0             1       af    6.436250  42.789625   \n",
       "\n",
       "                                                 bio  purchased  \n",
       "0  Sodales \"vivamus\" in, risus molestie, egestas in.          0  \n",
       "1                             Pellentesque arcu sed.          1  \n",
       "2                   Neque odio, in nulla, lorem nec.          0  \n",
       "3                                 Lorem non pretium.          0  \n",
       "4                                  Sem dictum dolor.          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'satisfaction' to be on a scale from -2 to +2\n",
    "data['satisfaction'] = data['satisfaction'].replace(['very low', 'low', 'neutral', 'high', 'very high'], \n",
    "                                                    [-2, -1, 0, 1, 2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>income</th>\n",
       "      <th>bio</th>\n",
       "      <th>purchased</th>\n",
       "      <th>location_a</th>\n",
       "      <th>location_af</th>\n",
       "      <th>location_aus</th>\n",
       "      <th>location_eu</th>\n",
       "      <th>location_in</th>\n",
       "      <th>location_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.952074</td>\n",
       "      <td>-19.486208</td>\n",
       "      <td>Sodales \"vivamus\" in, risus molestie, egestas in.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.529518</td>\n",
       "      <td>51.284180</td>\n",
       "      <td>Pellentesque arcu sed.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.254526</td>\n",
       "      <td>97.345260</td>\n",
       "      <td>Neque odio, in nulla, lorem nec.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.924077</td>\n",
       "      <td>80.242606</td>\n",
       "      <td>Lorem non pretium.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.436250</td>\n",
       "      <td>42.789625</td>\n",
       "      <td>Sem dictum dolor.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  satisfaction  time_spent     income  \\\n",
       "0  63.0             0    3.952074 -19.486208   \n",
       "1  28.0             0    3.529518  51.284180   \n",
       "2  37.0             1    4.254526  97.345260   \n",
       "3  42.0             1    4.924077  80.242606   \n",
       "4  56.0             1    6.436250  42.789625   \n",
       "\n",
       "                                                 bio  purchased  location_a  \\\n",
       "0  Sodales \"vivamus\" in, risus molestie, egestas in.          0           0   \n",
       "1                             Pellentesque arcu sed.          1           0   \n",
       "2                   Neque odio, in nulla, lorem nec.          0           0   \n",
       "3                                 Lorem non pretium.          0           0   \n",
       "4                                  Sem dictum dolor.          0           0   \n",
       "\n",
       "   location_af  location_aus  location_eu  location_in  location_na  \n",
       "0            0             0            1            0            0  \n",
       "1            0             0            0            0            0  \n",
       "2            0             0            0            0            0  \n",
       "3            0             0            0            0            0  \n",
       "4            1             0            0            0            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can convert location into dummy variables by binarizing:\n",
    "for value in np.unique(data['location'])[0:-1]:\n",
    "    data['location_' + value] = pd.Series(data['location'] == value, dtype=int)\n",
    "data = data.drop(['location'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>income</th>\n",
       "      <th>purchased</th>\n",
       "      <th>location_a</th>\n",
       "      <th>location_af</th>\n",
       "      <th>location_aus</th>\n",
       "      <th>location_eu</th>\n",
       "      <th>location_in</th>\n",
       "      <th>...</th>\n",
       "      <th>bio_velit</th>\n",
       "      <th>bio_venenatis</th>\n",
       "      <th>bio_vestibulum</th>\n",
       "      <th>bio_vitae</th>\n",
       "      <th>bio_vivamus</th>\n",
       "      <th>bio_viverra</th>\n",
       "      <th>bio_voluptatem</th>\n",
       "      <th>bio_volutpat</th>\n",
       "      <th>bio_vulputate</th>\n",
       "      <th>bio_wisi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.952074</td>\n",
       "      <td>-19.486208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.529518</td>\n",
       "      <td>51.284180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.254526</td>\n",
       "      <td>97.345260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.924077</td>\n",
       "      <td>80.242606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.436250</td>\n",
       "      <td>42.789625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  satisfaction  time_spent     income  purchased  location_a  \\\n",
       "0  63.0             0    3.952074 -19.486208          0           0   \n",
       "1  28.0             0    3.529518  51.284180          1           0   \n",
       "2  37.0             1    4.254526  97.345260          0           0   \n",
       "3  42.0             1    4.924077  80.242606          0           0   \n",
       "4  56.0             1    6.436250  42.789625          0           0   \n",
       "\n",
       "   location_af  location_aus  location_eu  location_in    ...     bio_velit  \\\n",
       "0            0             0            1            0    ...             0   \n",
       "1            0             0            0            0    ...             0   \n",
       "2            0             0            0            0    ...             0   \n",
       "3            0             0            0            0    ...             0   \n",
       "4            1             0            0            0    ...             0   \n",
       "\n",
       "   bio_venenatis  bio_vestibulum  bio_vitae  bio_vivamus  bio_viverra  \\\n",
       "0              0               0          0            1            0   \n",
       "1              0               0          0            0            0   \n",
       "2              0               0          0            0            0   \n",
       "3              0               0          0            0            0   \n",
       "4              0               0          0            0            0   \n",
       "\n",
       "   bio_voluptatem  bio_volutpat  bio_vulputate  bio_wisi  \n",
       "0               0             0              0         0  \n",
       "1               0             0              0         0  \n",
       "2               0             0              0         0  \n",
       "3               0             0              0         0  \n",
       "4               0             0              0         0  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last up is our text data, let's use a binary vectorizer to convert these to numeric\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the vectorizer\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "binary_vectorizer.fit(data['bio'])\n",
    "\n",
    "# I want to convert the numeric text data into a pandas DataFrame with meaninful column names. \n",
    "# To do this, I need to create a list of column headers. I will parse through the output of the\n",
    "# vocabulary to figure out the order and set column names.\n",
    "vocabulary = binary_vectorizer.vocabulary_\n",
    "bv_columns = list(range(len(vocabulary)))\n",
    "for word in vocabulary:\n",
    "    bv_columns[vocabulary[word]] = \"bio_\" + word\n",
    "\n",
    "# Transform the data using the vectorizer, convert it to dense, put it into pandas with our column names\n",
    "bio_numeric = pd.DataFrame(binary_vectorizer.transform(data['bio']).todense(), columns=bv_columns)\n",
    "\n",
    "# Merge the data DataFrame and the text DataFrame\n",
    "data = pd.concat([data, bio_numeric], axis=1)\n",
    "\n",
    "# Drop the raw string data entirely\n",
    "data = data.drop(['bio'], axis=1)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not required, you will often see people place their target variable into a Python variable called `Y` and to put all their predictors into `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['purchased'], axis=1)\n",
    "Y = data['purchased']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Semi-structured Data\n",
    "Some of you will have semi-structured data in the project. Often text is considered to be \"unstructured\" data (even though it contains vast amounts of lingustic structure).  \"Semi-structured\" refers to data that has some explicit structure (rather than just implicit linguistic structure), but it is not fully structured as tables, rows, and columns\n",
    "\n",
    "For example, web pages are structured, somewhat, with HTML tags. Within a page, the structure may be quite regular, and a set of pages from the same site may have similar structure.  On the other hand, the structure on different pages or different sites can be dramatically different. You can use regular expressions to parse data out of an HTML page. \n",
    "\n",
    "We can also use the BeautifulSoup package to parse data out of html (and xml too).  For example, let's extract the products for sale on this Etsy page: https://www.etsy.com/search?q=lamp\n",
    "\n",
    "You can read more about beautiful soup in many places. Here is a tutorial: http://web.stanford.edu/~zlotnick/TextAsData/Web_Scraping_with_Beautiful_Soup.html\n",
    "\n",
    "Notice you can uncomment out the print line to view the raw html returned. You can experiment with different tags etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>seller</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.95</td>\n",
       "      <td>Edison Lamp / Industrial Lamp/ Industrial Desk...</td>\n",
       "      <td>Edison Lamp / Industrial Lamp/ Industrial Desk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.00</td>\n",
       "      <td>Selenite Skyscraper Lamp</td>\n",
       "      <td>Selenite Skyscraper Lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.95</td>\n",
       "      <td>Edison Lamp / Industrial Lamp/ Industrial Desk...</td>\n",
       "      <td>Edison Lamp / Industrial Lamp/ Industrial Desk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.00</td>\n",
       "      <td>Selenite Skyscraper Lamp</td>\n",
       "      <td>Selenite Skyscraper Lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160.00</td>\n",
       "      <td>Handmade, Modern, Origami-inspired Lamp/Lighting</td>\n",
       "      <td>Handmade, Modern, Origami-inspired Lamp/Lighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.95</td>\n",
       "      <td>Edison Lamp / Industrial Lamp/ Industrial Desk...</td>\n",
       "      <td>Edison Lamp / Industrial Lamp/ Industrial Desk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65.00</td>\n",
       "      <td>Selenite Skyscraper Lamp</td>\n",
       "      <td>Selenite Skyscraper Lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>160.00</td>\n",
       "      <td>Handmade, Modern, Origami-inspired Lamp/Lighting</td>\n",
       "      <td>Handmade, Modern, Origami-inspired Lamp/Lighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1,362.48</td>\n",
       "      <td>Ceiling lamp of old oak branch.</td>\n",
       "      <td>Ceiling lamp of old oak branch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.71</td>\n",
       "      <td>Moon Night Light | Moon Lamp Gift | 3D Moon La...</td>\n",
       "      <td>Moon Night Light | Moon Lamp Gift | 3D Moon La...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price                                             seller  \\\n",
       "0     84.95  Edison Lamp / Industrial Lamp/ Industrial Desk...   \n",
       "1     65.00                           Selenite Skyscraper Lamp   \n",
       "2     84.95  Edison Lamp / Industrial Lamp/ Industrial Desk...   \n",
       "3     65.00                           Selenite Skyscraper Lamp   \n",
       "4    160.00   Handmade, Modern, Origami-inspired Lamp/Lighting   \n",
       "5     84.95  Edison Lamp / Industrial Lamp/ Industrial Desk...   \n",
       "6     65.00                           Selenite Skyscraper Lamp   \n",
       "7    160.00   Handmade, Modern, Origami-inspired Lamp/Lighting   \n",
       "8  1,362.48                    Ceiling lamp of old oak branch.   \n",
       "9     27.71  Moon Night Light | Moon Lamp Gift | 3D Moon La...   \n",
       "\n",
       "                                               title  \n",
       "0  Edison Lamp / Industrial Lamp/ Industrial Desk...  \n",
       "1                           Selenite Skyscraper Lamp  \n",
       "2  Edison Lamp / Industrial Lamp/ Industrial Desk...  \n",
       "3                           Selenite Skyscraper Lamp  \n",
       "4   Handmade, Modern, Origami-inspired Lamp/Lighting  \n",
       "5  Edison Lamp / Industrial Lamp/ Industrial Desk...  \n",
       "6                           Selenite Skyscraper Lamp  \n",
       "7   Handmade, Modern, Origami-inspired Lamp/Lighting  \n",
       "8                    Ceiling lamp of old oak branch.  \n",
       "9  Moon Night Light | Moon Lamp Gift | 3D Moon La...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Open the page and soup-it\n",
    "import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-Agent', 'Mozilla/5.0')]\n",
    "page = opener.open('https://www.etsy.com/search?q=lamp')\n",
    "\n",
    "soup = bs4.BeautifulSoup(page.read(), \"html.parser\")\n",
    "\n",
    "#print(soup)\n",
    "\n",
    "#print (soup.findAll('div',{'class':'prolist display-inline-block listing-link '}) )\n",
    "\n",
    "# We will collect the title, seller, and price of each product\n",
    "    \n",
    "items = {'title': [], 'seller': [], 'price': []}\n",
    "for title, seller, price in zip(soup.findAll('p',{'class':'text-gray text-truncate mb-xs-0 text-body'}), \n",
    "                        soup.findAll('p',{'class':'text-gray text-truncate mb-xs-0 text-body'}), \n",
    "                        soup.findAll('span',{'class':'currency-value'})):\n",
    "    \n",
    "    items['title'].append(title.text.strip())\n",
    "    items['seller'].append(seller.text.strip())\n",
    "    items['price'].append(price.text.strip())\n",
    "\n",
    "    \n",
    "# Convert to a pandas DataFrame\n",
    "etsy_items = pd.DataFrame(items)\n",
    "\n",
    "etsy_items.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "We've covered two different methods of modeling: supervised and unsupervised.\n",
    "\n",
    "### 4.1. Supervised\n",
    "Most of what we've done this semester involves having **labeled** data. For these data, we have a set of records where we know the value of the target variable. This allows us to learn some relationship between our feature set and the target variable. We've covered five machine learning algorithms that can do this. Here is a brief overview of the modeling methods for classification (regression overview would be similar).\n",
    "\n",
    "<table>\n",
    "<tr><td>Model</td>\n",
    "<td>Overview</td>\n",
    "<td>Pros</td>\n",
    "<td>Cons</td>\n",
    "<td>Use Case</td></tr>\n",
    "\n",
    "<tr><td>Tree Structured</td>\n",
    " <td>Partitions the data space by carving it up into (hyper)rectangles, creating a \"supervised segmentation\" -- that is, a segmentation of the space driven by differences in the value of the target variable.  Each segment comes with an estimate of the probability of class membership for data points falling in the segment.<br />\n",
    " \n",
    " </td>\n",
    " <td>- Non-linear model (low bias) <br />\n",
    "     - Tree-structure can be interpretable <br />\n",
    "     - In theory can fit arbitrary functions of the input features to arbitrary precision<br />\n",
    "     - Fast test for non-linearity in a data set<br />\n",
    "     - Fast and easy to apply, as long as tree isn't too big<br />\n",
    "     - Often an attractive alternative to clustering, when a target variable exists<br />\n",
    "     - The basis for many state-of-the-art methods (e.g., random forests)\n",
    "     </td>\n",
    " <td>- Separating planes will be perpendicular to a feature, thus unnatural for curved boundaries<br />\n",
    "     - Trees can be very complex (thus, maybe not so interpretable)<br />\n",
    "     - Prone to overfitting</td>\n",
    " <td>- Data with mixed numeric and categorical features, and not a huge number of relevant features</td></tr>\n",
    " \n",
    "<tr><td>Logistic Regression</td>\n",
    " <td>Creates a hyperplane (linear function) separating the classes, plus an estimate of class probability based on the distance of a point from the hyperplane. </td>\n",
    " <td>- Coefficients to interpret<br />\n",
    "     - Low overfitting (low variance)<br />\n",
    "     - Can be effective even with massive numbers of features<br />\n",
    "     - Fast and easy in \"use phase\"</td>\n",
    " <td>- Coefficients to interpret<br />\n",
    "     - Can be slow to train (need to think about the optimization routine \"under the hood\")<br />\n",
    "     - Will only learn \"linear part\" of true concept (high bias)</td>\n",
    " <td>- Always try it</td></tr>\n",
    "\n",
    "\n",
    "<tr><td>SVM</td>\n",
    " <td>Very similar to logistic regression, without the probability estimate.  Creates a hyperplane that can separate the data with the maximal **margin**.</td>\n",
    " <td>- Different \"kernels\" available, that can turn it into a non-linear method</td>\n",
    " <td>- Can be sloooooow </td>\n",
    " <td>- Try it for text data</td></tr>\n",
    "\n",
    "<tr><td>Naive Bayes</td>\n",
    " <td>Applies Bayes Theorem, based on simple counts, to estimate class membership probabilities.</td>\n",
    " <td>- Fast training<br />\n",
    "     - Super easy to get running fast in most production environments<br />\n",
    "     - Can be implemented with SQL queries (or in Excel!)</td>\n",
    " <td>- Treats the features as independent of each other within each class<br />\n",
    "     - Actual probabilities often are quite biased\n",
    "     </td>\n",
    " <td>- Text data<br />\n",
    "     - High-dimensional behavior data (e.g., locations, URLs, Likes, ...)</td></tr>\n",
    "\n",
    "<tr><td>k-NN</td>\n",
    " <td>Reasons about a case by finding the $k$-closest records and combines their labels (e.g., with majority voting or an average).</td>\n",
    " <td>- Works with any number of labels<br />\n",
    "     - Fast \"learning\" (lazy)</td>\n",
    " <td>- Slow prediction</td>\n",
    " <td>- When choosing \"the closest cases\" makes sense to the users/stakeholders</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Unsupervised\n",
    "Unsupervised algorithms are used for data where there is no target variable or no labels for your target variable.  \n",
    "\n",
    "<table>\n",
    "<tr><td>Model</td>\n",
    "<td>Overview</td>\n",
    "<td>Pros</td>\n",
    "<td>Cons</td></tr>\n",
    "\n",
    "<tr><td>K-Means</td>\n",
    " <td>Creates **$k$ clusters** where each record belongs to the cluster with the closest mean (center)</td>\n",
    " <td>- Fast (relatively)</td>\n",
    " <td>- k is very likely unknown<br />\n",
    "     - Nondeterministic</td></tr>\n",
    " \n",
    "<tr><td>Hierarchical Clustering</td>\n",
    " <td>Creates an increasing number of clusters by continually **merging clusters** that are closest together (clusters can be single records)</td>\n",
    " <td>- The number of clusters does not need to be preset</td>\n",
    " <td>- Various non-intuitive parameters under the hood</td></tr>\n",
    "\n",
    "<!--<tr><td>Dimensionality Reduction</td>\n",
    " <td>Takes a set of records with $M$ features and reduces it to the top $m$ features (that explain the most variance), where $m < M$.</td>\n",
    " <td></td>\n",
    " <td></td></tr>-->\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Implementation\n",
    "All of these algorithms have an implementation in sklearn. Some algorithms, like SVM, have multiple implementations. Let's import one implementation of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given you have imported your model, the general process for using the model is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "model.fit(X, Y) # there is no equal sign here!\n",
    "prediction = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't matter what model you are using, it is always the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Don't Forget!!\n",
      "\n",
      " 'Prediction' gives the class. \n",
      " Let's see the predicted classes of 5 observations (train):\n",
      "[0 1 0 0 0]\n",
      "\n",
      " 'Proba-Prediction' gives the score of the class. \n",
      " Let's see the predict_proba of 5 observations (train):\n",
      "\n",
      "[Prob. of being 0, Prob. of being  1]\n",
      "\n",
      "[[0.77694836 0.22305164]\n",
      " [0.42077041 0.57922959]\n",
      " [0.76607812 0.23392188]\n",
      " [0.94394373 0.05605627]\n",
      " [0.99231646 0.00768354]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, Y) # there is no equal sign here!\n",
    "prediction = model.predict(X)\n",
    "probabilities = model.predict_proba(X)\n",
    "\n",
    "print (\"\\n Don't Forget!!\")\n",
    "print (\"\\n 'Prediction' gives the class. \\n Let's see the predicted classes of 5 observations (train):\")\n",
    "print (prediction[0:5])\n",
    "print (\"\\n 'Proba-Prediction' gives the score of the class. \\n Let's see the predict_proba of 5 observations (train):\")\n",
    "print (\"\\n[Prob. of being 0, Prob. of being  1]\\n\")\n",
    "print (probabilities[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "How do we know if our model is any good? There are many ways of doing this! The \"best\" way depends critically on your particular use case.  Here are two example metrics for classification/ranking. \n",
    "\n",
    "<table>\n",
    "<tr><td>Metric</td>\n",
    " <td>Overview</td>\n",
    " <td>Pros</td>\n",
    " <td>Cons</td></tr>\n",
    "<tr><td>Accuracy</td>\n",
    " <td>The percentage of things you got correct.</td>\n",
    " <td>- Easy to calculate and interpret</td>\n",
    " <td>- Doesn't account for business costs<br />\n",
    " - Doesn't account for baseline</td></tr>\n",
    "<tr><td>ROC/AUC</td>\n",
    " <td>False positive rate vs. True positive rate.</td>\n",
    " <td>- Allows for fine-grained assessment<br />\n",
    " - Is independent of class \"skew\"</td>\n",
    " <td>- Can be difficult for non-data-scientists to understand<br />\n",
    " - Exploring multiple ROC curves can become messy</td></tr>\n",
    "</table>\n",
    "\n",
    "We spoke of other metrics in class: lift, precision, recall, mean squared error, etc.\n",
    "\n",
    "Accuracy, ROC curves, and area under the ROC curve calculations (as well as many others) are straight forward in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.909\n",
      "The AUC is 0.949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3d170e160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, Y)\n",
    "prediction = model.predict(X)\n",
    "probabilities = model.predict_proba(X)\n",
    "\n",
    "print (\"The accuracy is %.3f\" % accuracy_score(Y, prediction))\n",
    "print (\"The AUC is %.3f\" % roc_auc_score(Y, probabilities[:, 1]))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y, probabilities[:, 1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], '--')\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And don't forget to consider **lift** curves (e.g. the degree to which it “pushes up” the positive instances in a \n",
    "list above the negative instances) and **profits** too!!\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 70%\">\n",
    "<img src=\"images/lift.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 70%\">\n",
    "<img src=\"images/profits.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluation II (splitting)\n",
    "Why do we never want to train and evaluate on the same data? Overfitting! Our main \"tool\" (technique) to evaluate and avoid overfitting is by splitting the data, and then training and evaluating on different portions.  We can do this via a single train/test split, or via cross validation. Both of these methods are, again, built into sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.812\n",
      "The AUC is 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train/test splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.75)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "prediction = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)\n",
    "\n",
    "print (\"The accuracy is %.3f\" % accuracy_score(Y_test, prediction))\n",
    "print (\"The AUC is %.3f\" % roc_auc_score(Y_test, probabilities[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `cross_val_score()` function, we can assess models using cross validation in only one line. Check the [documentation](http://scikit-learn.org/stable/modules/model_evaluation.html) for a list of possible `scoring` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.834\n",
      "The AUC is 0.875\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "model = LogisticRegression()\n",
    "\n",
    "print (\"The accuracy is %.3f\" % np.mean(cross_val_score(model, X, Y, cv=5, scoring=\"accuracy\")))\n",
    "print (\"The AUC is %.3f\" % np.mean(cross_val_score(model, X, Y, cv=5, scoring=\"roc_auc\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Tuning and Complexity\n",
    "By default, all the modeling procedures we use in sklearn have some settings that manage how complex they allow the resulting models to be. We've studies quite a few of these complexity parameters (usually called hyper-parameters). The act of finding the \"best\" parameter is usually done through a procedure of \"hyper-parameter tuning\".  \n",
    "\n",
    "**IMPORTANTLY:** hyper-parameter tuning *should* be done on a data set separate from the final test set that will be used to report evaluation results.  Since hyper-parameter tuning is part of learning a model, if you don't separate out the final test set, you run the risk of not judging the overfitting done by the overall procedure.  *We sometimes ignore this when first learning about hyper-parameter tuning, because it is complicated.  You should not ignore it when applying these methods in practice.*\n",
    "\n",
    "<table>\n",
    "<tr><td>Model Type</td>\n",
    " <td>Parameter</td>\n",
    " <td>Explanation</td>\n",
    " <td>Good Range</td></tr>\n",
    "\n",
    "<tr><td>Tree</td>\n",
    " <td>max_depth</td>\n",
    " <td>Maximum number of levels to build</td>\n",
    " <td>[1, log<sub>2</sub>(# records)]</td></tr>\n",
    "\n",
    "<tr><td>Tree</td>\n",
    " <td>min_samples_split</td>\n",
    " <td>Minimum number of records that must be in a node for it to be split.</td>\n",
    " <td>[1, # records]</td></tr>\n",
    " \n",
    "<tr><td>Tree</td>\n",
    " <td>min_samples_leaf</td>\n",
    " <td>Minimum number of records that must be at a node to call it a leaf.</td>\n",
    " <td>[1, # records]</td></tr>\n",
    "\n",
    "<tr><td>LR</td>\n",
    " <td>C</td>\n",
    " <td>Regularization parameter. How heavily should the model be penalized for being complex?</td>\n",
    " <td>[10<sup>-10</sup>, 10<sup>10</sup>]</td></tr>\n",
    "\n",
    "<tr><td>SVM</td>\n",
    " <td>C</td>\n",
    " <td>Similar to logistic regression</td>\n",
    " <td>[10<sup>-10</sup>, 10<sup>10</sup>]</td></tr>\n",
    " \n",
    "<tr><td>NB</td>\n",
    " <td>alpha</td>\n",
    " <td>Smoothing constant. Essential to ensure 0 probabilities don't zero-out the product.  Used also to keep small counts from making a big difference.</td>\n",
    " <td>[0, ...]</td></tr>\n",
    " \n",
    "<tr><td>k-NN</td>\n",
    " <td>k</td>\n",
    " <td>Number of neighbors, usually odd to avoid ties</td>\n",
    " <td>[1, number_records]</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the training cross-validation:\n",
      "Maximum accuracy is 0.847 and occurred with parameter setting of 0.000e+00\n",
      "Maximum AUC is 0.888 and occurred with parameter setting of -1.000e+00\n",
      "\n",
      "On the held-out test set:\n",
      "Accuracy is 0.800 for model learned with parameter setting of 0.000e+00\n",
      "Maximum AUC is 0.856 for model learned with parameter setting of -1.000e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train/test splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.75)\n",
    "\n",
    "hyper_parameters = range(-10, 11)\n",
    "accuracies = []\n",
    "aucs = []\n",
    "test_accs = []\n",
    "test_aucs = []\n",
    "\n",
    "for hyper_parameter in hyper_parameters:\n",
    "    c = np.power(10.0, hyper_parameter)\n",
    "    \n",
    "    model = LogisticRegression(C=c)\n",
    "    \n",
    "    accuracies.append(np.mean(cross_val_score(model, X_train, Y_train, cv=5, scoring=\"accuracy\")))\n",
    "    aucs.append(np.mean(cross_val_score(model, X_train, Y_train, cv=5, scoring=\"roc_auc\")))\n",
    "    \n",
    "    #Now, also get eval on test set, but only look at the one that's best from training cv\n",
    "    model.fit(X_train, Y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    test_accs.append(accuracy_score(Y_test, prediction))\n",
    "    test_aucs.append(roc_auc_score(Y_test, probabilities[:, 1]))\n",
    "    \n",
    "\n",
    "print (\"On the training cross-validation:\")\n",
    "print (\"Maximum accuracy is %.3f and occurred with parameter setting of %.3e\" % (np.max(accuracies), hyper_parameters[np.argmax(accuracies)]))\n",
    "print (\"Maximum AUC is %.3f and occurred with parameter setting of %.3e\" % (np.max(aucs), hyper_parameters[np.argmax(aucs)]))\n",
    "\n",
    "best_acc = np.argmax(accuracies)\n",
    "best_auc = np.argmax(aucs)\n",
    "\n",
    "print ()\n",
    "print (\"On the held-out test set:\")\n",
    "print (\"Accuracy is %.3f for model learned with parameter setting of %.3e\" % (test_accs[best_acc], hyper_parameters[np.argmax(accuracies)]))\n",
    "print (\"Maximum AUC is %.3f for model learned with parameter setting of %.3e\" % (test_aucs[best_auc], hyper_parameters[np.argmax(aucs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
