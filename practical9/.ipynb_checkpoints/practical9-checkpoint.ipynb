{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 9\n",
    "\n",
    "## Text Mining\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas to read in data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import models and evaluation functions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Import vectorizers to turn text into numeric\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import plotting\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "We are going to look at some Amazon reviews and classify them into positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "The file `data/books.csv` contains 2,000 Amazon book reviews. The data set contains two features: the first column (contained in quotes) is the review text. The second column is a binary label indicating if the review is positive or negative.\n",
    "\n",
    "Let's take a quick look at the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -3 data/books.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data into a pandas data frame. You'll notice two new attributed in `pd.read_csv()` that we've never seen before. The first, `quotechar` is tell us what is being used to \"encapsulate\" the text fields. Since our review text is surrounding by double quotes, we let pandas know. We use a `\\` since the quote is also used to surround the quote. This backslash is known as an escape character. We also let pandas now this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/books.csv\", quotechar=\"\\\"\", escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text as a set of features\n",
    "Going from text to numeric data is very easy. Let's take a look at how we can do this. We'll start by separating out our X and Y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = data['review_text']\n",
    "Y = data['positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will turn `X_text` into just `X` -- a numeric representation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a vectorizer that will track text as binary features\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Let the vectorizer learn what tokens exist in the text data\n",
    "binary_vectorizer.fit(X_text)\n",
    "\n",
    "# Turn these tokens into a numeric matrix\n",
    "X = binary_vectorizer.transform(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "We have a ton of features, let's use them in some different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Use this model and our data to get 5-fold cross validation AUCs\n",
    "aucs = cross_validation.cross_val_score(logistic_regression, X, Y, scoring=\"roc_auc\", cv=5)\n",
    "\n",
    "# Print out the average AUC rounded to three decimal points\n",
    "print \"Area under the ROC curve for our classifier is \" + str(round(np.mean(aucs), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using full counts instead of a binary representation. I've just copy and pasted what is above and removed the `binary=True` from the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorizer that will track text as binary features\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Let the vectorizer learn what tokens exist in the text data\n",
    "count_vectorizer.fit(X_text)\n",
    "\n",
    "# Turn these tokens into a numeric matrix\n",
    "X = count_vectorizer.transform(X_text)\n",
    "\n",
    "# Create a model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Use this model and our data to get 5-fold cross validation AUCs\n",
    "aucs = cross_validation.cross_val_score(logistic_regression, X, Y, scoring=\"roc_auc\", cv=5)\n",
    "\n",
    "# Print out the average AUC rounded to three decimal points\n",
    "print \"Area under the ROC curve for our classifier is \" + str(round(np.mean(aucs), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorizer that will track text as binary features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Let the vectorizer learn what tokens exist in the text data\n",
    "tfidf_vectorizer.fit(X_text)\n",
    "\n",
    "# Turn these tokens into a numeric matrix\n",
    "X = tfidf_vectorizer.transform(X_text)\n",
    "\n",
    "# Create a model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Use this model and our data to get 5-fold cross validation AUCs\n",
    "aucs = cross_validation.cross_val_score(logistic_regression, X, Y, scoring=\"roc_auc\", cv=5)\n",
    "\n",
    "# Print out the average AUC rounded to three decimal points\n",
    "print \"Area under the ROC curve for our classifier is \" + str(round(np.mean(aucs), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group work\n",
    "#### Features\n",
    "Tfidf is looking pretty good! How about adding n-grams? Stop words? Lowercase transforming?\n",
    "\n",
    "`CountVectorizer()` and `TfidfVectorizer()` can be modified to handle all of these things. Work in groups and try a few different combinations of these settings for anything you want: binary counts, numeric counts, tf-idf counts. Here is how you would use these settings:\n",
    "\n",
    "- \"`ngram_range=(1,2)`\": would include unigrams and bigrams\n",
    "- \"`stop_words=\"english\"`\": would use a standard set of English stop words\n",
    "- \"`lowercase=False`\": would turn off lowercase transformation (it is actually on by default)!\n",
    "\n",
    "You can use some of these like this:\n",
    "\n",
    "`tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), lowercase=False)`\n",
    "\n",
    "#### Models\n",
    "You can also swap out the line creating a logistic regression with one making a naive Bayes. This is also one line:\n",
    "\n",
    "`naive_bayes = BernoulliNB()`\n",
    "\n",
    "You can then go ahead and use `naive_bayes` inplace of `logistic_regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with your teams here!\n",
    "# Try different features, models, or both!\n",
    "# What is the highest AUC you can get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We have examined two ways of dealing with categorical data: binarizing/dummy variables and numerical scaling. We will practice these here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/categorical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing\n",
    "Get a list of features you want to binarize, go through each feature and create new features for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_binarize = [\"Gender\", \"Marital\"]\n",
    "\n",
    "# Go through each feature\n",
    "for feature in features_to_binarize:\n",
    "    # Go through each level in this feature (except the last one!)\n",
    "    for level in data[feature].unique()[0:-1]:\n",
    "        # Create new feature for this level\n",
    "        data[feature + \"_\" + level] = pd.Series(data[feature] == level, dtype=int)\n",
    "    # Drop original feature\n",
    "    data = data.drop([feature], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric scaling\n",
    "We can also replace text levels with some numeric mapping we create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Satisfaction'] = data['Satisfaction'].replace(['Very Low', 'Low', 'Neutral', 'High', 'Very High'], \n",
    "                                                    [-2, -1, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
